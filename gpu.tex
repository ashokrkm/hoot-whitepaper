\textbf{G}raphics \textbf{P}rocessing \textbf{U}nits (GPUs) can significantly accelerate the training process for many deep learning models. For example, GPUs can accelerate the training process for deep learning models designed for image classification, video analysis, and natural language processing because the training process for those models involves the compute-intensive task of matrix multiplication and other operations that can take advantage of a GPU's massively parallel architecture. This architecture is well-suited for algorithms designed to address embarrassingly parallel workloads across more than a dozen areas of computer science and other fields, including live streaming, speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery.

GPUCoin IPCN takes computations and maps them onto a wide variety of different hardware platforms, ranging from running inference on mobile device platforms such as Android and iOS to modest-sized training and inference systems using single machines containing one or many GPU cards to large-scale training systems running on hundreds of specialized machines with thousands of GPUs. Having a single system that can span such a broad range of platforms significantly simplifies the real-world use of GPUs, as we have found that having separate systems for large-scale GPU training and small-scale deployment leads to significant maintenance burdens and leaky abstractions. 

Training a deep learning model that involves intensive compute tasks on extremely large datasets can take days to run on a single processor. However, if you design your program to offload those tasks to one or more GPUs, you can reduce training time to hours instead of days. GPUCoin IPCN network is designed to address such embarrassingly parallel workloads and use GPUCoin GPC token as the currency of exchange \& transaction fees for these workloads using block-chain smart contracts. 
